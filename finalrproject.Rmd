---
title: "R Notebook"
output: html_notebook
---

1.3.2 Industrial and Labor Relations
In 1947, the United States Congress passed the Taft-Hartley Amendments to the
Wagner Act. The original Wagner Act had permitted the unions to use a Closed
Shop Contract unless prohibited by state law. The Taft-Hartley Amendments
made the use of Closed Shop Contract illegal and gave individual states the right to prohibit union shops as well. These right-to-work laws have caused a wave of concern throughout the labor movement. 
A question of interest here is: What are the effects of these laws on the cost of living for a four-person family living on an intermediate budget in the United States? 

To answer this question a data set consisting of 38 geographic locations has been assembled from various sources.
The variables used are defined in Table 1.2. The Right-To-Work Laws data are
given in Table 1.3 and can also be found at the book's Website.

Variable
COL     Cost of living for a four-person family
PD      Population density (person per square mile)
URate   State unionization rate in 1978
Pop     Population in 1975
Taxes   Property taxes in 1972
Income  Per capita income in 1974
RTWL    Indicator variable (1 if there are right-to-work laws in the state and 0                  otherwise)

```{r}

library(dplyr)
library(scatterplot3d)
library(psych)
library(ggplot2)
library(car)
library(gclus)
library(GGally)
library(fields)
require(ggplot2)
require(ggmap)
require(maps)
```
```{r}
library(ggplot2)
library(ggmap)
library(maps)
library(mapdata)
```

#########################
Start: Getting data ready
```{r}
data <- read.delim("P005.txt")
```
Here, I saved the geocode, longitude and lat, in a csv so we didn't have to run geocode everytime.
```{r}
lonlat <- read.csv("lonlat.csv")
lonlat<-lonlat[,-1]
```
Adding the lon and lat variables to data.
```{r}
data$lon <- lonlat$lon
data$lat <- lonlat$lat
data$RTWL <- factor(data$RTWL)
```
Note: Wahsington was ran as washington state in geocode, so needed to run it as Washintion DC
```{r}
data[,1]<- as.character(data[,1])
data[36,1] <- "Washington DC"
```
```{r}
data[36,9] <- -77.03687	
data[36,10] <- 38.90719

```
End: getting data ready
#########################################
Start data vis
```{r}
 #Making a Basic scatter plot matrix
 
 scatterplotMatrix(~COL+PD+URate+Pop+Taxes+Income+RTWL+lon+lat ,data=data, smooth = FALSE, ellipse=
 FALSE, main="Simple Scatterplot Matrix")

```


```{r}
data1.1 <- data
data1.1$RTWL <- as.numeric(data1.1$RTWL)
```
```{r}
dta.r <- abs(cor(data1.1[,-c(1,6)] )) # get correlations
dta.col <- dmat.color(dta.r) # get colors
# reorder variables so those with highest correlation
# are closest to the diagonal
dta.o <- order.single(dta.r) 
cpairs(data1.1[,-c(1,6)], dta.o, panel.colors=dta.col, gap=.5,
main="Variables Ordered and Colored by Correlation" )

dta.r
```

```{r}

# Correlation plot
ggcorr(data1.1[,-c(1,6)], palette = "RdBu", label = TRUE)
```




```{r}
A6A9 <- ggplot(data, aes(x = COL, y = Income)) + geom_point() + geom_point(aes(color = factor(RTWL)))
A6A9

A6A10 <- ggplot(data, aes(x = URate, y = Taxes)) + geom_point() + geom_point(aes(color = factor(RTWL)))
A6A10

A6A10 <- ggplot(data, aes(x = URate, y = Taxes)) + geom_point() + geom_point(aes(color = factor(RTWL)))
A6A10

A6A11 <- ggplot(data, aes(x = COL, y = PD)) + geom_point() + geom_point(aes(color = factor(RTWL)))
A6A11
```

```{r}

```



```{r}
usa <- map_data("usa") 
ggplot() + geom_polygon(data = usa, aes(x=long, y = lat, group = group)) + 
  coord_fixed(1.3) +
    geom_point( aes(x = data$lon, y = data$lat, color=factor(data$RTWL), size=data$COL)) +
  geom_text(data=data, aes(x=lon,y=lat, label = data$City),hjust=0, vjust=0, color="green", size= 2.9)
  

```
```{r}
usa <- map_data("usa")
ggplot() + geom_polygon(data = usa, aes(x=long, y = lat, group = group)) + 
  coord_fixed(1.3) +
    geom_point( aes(x = data$lon, y = data$lat, color=(data$COL), size=data$Income)) 
```

This is a 'picture of a' map

End data vis
#########################################

Start: AIC model slection 
Running the AIC for model WITHOUT longitude and Latitude
```{r}
model_null <- lm( COL~1, data = data)
model_full <- lm( COL~PD*URate*Pop*Taxes*Income*RTWL, data=data)


```

```{r}
step(model_null, scope=list(lower=model_null, 
                        upper=model_full),
     direction="forward")
```
Note: Correcting the Washingtion to Wahington DC issue changed the AIC result. We no longer need lat in the model.
```{r}
model1 <- lm(formula = COL ~ RTWL + Pop + URate + Income + PD + RTWL:URate + 
    RTWL:Income + URate:Income, data = data)
  summary(model1)
```

AIC with lon and lat
```{r}
model_null2 <- lm( COL~1, data = data)
model_full2 <- lm( COL~PD*URate*Pop*Taxes*Income*RTWL*lon*lat, data=data)
```

```{r}
step(model_null2, scope=list(lower=model_null2, 
                        upper=model_full2),
     direction="forward")
```
```{r}
model2 <- lm(formula = COL ~ RTWL + Pop + lon + Income + URate + PD + lon:Income, data = data)
```
```{r}
summary(model2)
```
 COL ~ RTWL + Pop + lon + Income + URate + PD + lon:Income
 
# Col = -538+ -48(RTWL) + 6.7e-06(Pop) + -8(lon) + .14(Income) + -5(URate) + .027(PD) + 1.3e-03(lon)(Income)

The interaction term means: the rate of change of COL with respect to Income depends on the lon value. From left to right, we go from lon=-120 to -80, so the partial derivative with respect ot Income, moving from left to right, goes from 1.3e-03(-120)=-0.156 to 1.3e-03(-80)=-0.104. In the west, lon=-120, say, if income= 1, then 
COS = -0.156(income) + -8(-120) + (some other stuff, call "c"); 
whereas in the eastm lon=-80, if income=1, then 
COS=-0.104(Income) + -8(-80) + (some other stuff). 
960 + c,  640 + c
So, given the same Income, the cost of living in the west is higher than

```{r}
COSw <- as.data.frame( c(0:100000, by=1))
COSe <-as.data.frame( c(0:100000, by=1))
COSw[,2] <- -0.156*(c(0:100000, by=1)) + -8*(-120)
COSe[,2] <- -0.104*(c(0:100000,by=1)) + -8*(-80)
```
```{r}
colnames(COSw)<-c("x","y")
colnames(COSe)<-c("x","y")
```
```{r}
inc <- c(-300:300, by=50)
```
```{r}

A6A12 <- ggplot(data, aes(x = lon, y = COL)) + geom_point() + geom_point(aes(color = Income))
A6A12
```
for (i in 1:length(inc)) {
abline( -8*(inc[i]), 1.3e-03*(inc[i]))
}

```{r}
abline( -8*(-120), -.156)
abline(-8*(-80),-.104)
```

```{r}
library(colorRamps)  
library(grDevices)
```
```{r}
lon <- seq(min(data$lon),max(data$lon), by=10)
Income <- seq(min(data$Income),max(data$Income), by=10)
gg <- expand.grid(lon=lon, Income=Income)
```
```{r}
# prediction from the linear model
gg$COL <-predict(fit,newdata=gg)
```
```{r}
jet.colors <- colorRampPalette(matlab.like(9))
ggplot(gg, aes(x=lon, y=Income, z=COL))+
  stat_contour(aes(color=..level..),binwidth=5, size=2)+
  scale_color_gradientn(colours=jet.colors(8))
```

> 1.336e-03*(-80)+1.423e-01
[1] 0.03542
> 1.336e-03*(-120)+1.423e-01
[1] -0.01802

```{r}
summary(fit)
```




End: AIC model selection
######################
Start Model Assumption Check 


Normal prob plot
```{r}
# qq plot for studentized resid
qqPlot(model1, main="QQ Plot")
```

Pred. vs StRes.
```{r}
residualPlots(model1)
```

```{r}
# Assessing Outliers
outlierTest(model1) # Bonferonni p-value for most extreme obs
qqPlot(model1, main="QQ Plot") #qq plot for studentized resid 
leveragePlots(model1) # leverage plots
```
```{r}
# Influential Observations
# added variable plots 
avPlots(model1)
# Cook's D plot
# identify D values > 4/(n-k-1) 
cutoff <- 4/((nrow(mtcars)-length(model1$coefficients)-2)) 
plot(model1, which=4, cook.levels=cutoff)
# Influence Plot 
influencePlot(model1,	id="identify", main="Influence Plot", sub="Circle size is proportial to Cook's Distance" )
```

```{r}
# Normality of Residuals
# qq plot for studentized resid
qqPlot(model1, main="QQ Plot")
# distribution of studentized residuals
library(MASS)
sresid <- studres(model1) 
hist(sresid, freq=FALSE, 
   main="Distribution of Studentized Residuals")
xmodel1<-seq(min(sresid),max(sresid),length=40) 
ymodel1<-dnorm(xmodel1) 
lines(xmodel1, ymodel1)
```

```{r}
# Evaluate homoscedasticity
# non-constant error variance test
ncvTest(model1)
# plot studentized residuals vs. model1ted values 
spreadLevelPlot(model1)
```

```{r}
# Evaluate Collinearity
vif(model1) # variance inflation factors 
sqrt(vif(model1)) > 2 # problem?
```


```{r}
# Test for Autocorrelated Errors
durbinWatsonTest(model1)
```

```{r}
# Global test of model assumptions
library(gvlma)
gvmodel <- gvlma(model1) 
summary(gvmodel)
```

```{r}

```

```{r}

```

```{r}

```



